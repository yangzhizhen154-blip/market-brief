# -*- coding: utf-8 -*-
"""market brief -AE

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Pltvg5vF9tMAm1k_ixMKLAfd94IacYWA
"""



import re
import os
import json
from google.oauth2 import service_account
from googleapiclient.discovery import buildfrom datetime import datetime, timezone, timedelta

import yfinance as yf
import feedparser
from dateutil import parser as dateparser


from googleapiclient.discovery import build

# =========================
# AE SETTINGS
# =========================
DOC_ID = "1CRVukhcnzGkEEkfMdxlVeYd-3uPsn5gO_IPYVIoUx5Y"   # ✅ AE Doc
TITLE = "Asian & Europe markets(4.30 Pm)"
LOOKBACK_HOURS = 12
PRICE_DAYS = 7

EQUITIES = {
    "Nikkei 225": "^N225",
    "Hang Seng": "^HSI",
    "上证指数": "000001.SS",
    "Euro Stoxx 50": "^STOXX50E",
    "FTSE 100": "^FTSE",
}

BONDS = {
    "US 10Y": "^TNX",   # yield already in %
    "US 30Y": "^TYX",
}

FX = {
    "EUR/USD": "EURUSD=X",
    "USD/JPY": "JPY=X",
    "USD/HKD": "HKD=X",
}

COMMODITIES = {
    "Gold": "GC=F",
    "Crude oil": "CL=F",
}

RSS_FEEDS = [
    "https://www.reutersagency.com/feed/?best-topics=business-finance&post_type=best",
    "https://feeds.bbci.co.uk/news/business/rss.xml",
    "https://www.ft.com/rss/home",
    "https://www.cnbc.com/id/100003114/device/rss/rss.html",
    "https://finance.yahoo.com/news/rssindex",
]

# -------------------------
# PRICE HELPERS
# -------------------------
def fetch_last_two_closes(ticker: str):
    data = yf.download(ticker, period=f"{PRICE_DAYS}d", interval="1d", progress=False)
    if data is None or data.empty or "Close" not in data:
        return None, None
    closes = data["Close"].dropna()
    if len(closes) < 2:
        return None, None
    return float(closes.iloc[-1]), float(closes.iloc[-2])

def pct_change(last, prev):
    if last is None or prev is None or prev == 0:
        return None
    return (last - prev) / prev * 100.0

def get_block(block, kind="price"):
    """
    kind="price": normal assets -> (name, level, pct)
    kind="yield": ^TNX/^TYX -> (name, level(%), bp_change)
    """
    rows = []
    for name, ticker in block.items():
        last, prev = fetch_last_two_closes(ticker)
        if last is None:
            rows.append((name, None, None))
            continue
        if kind == "yield":
            bp = (last - prev) * 100.0  # 0.01% = 1bp
            rows.append((name, last, bp))
        else:
            chg = pct_change(last, prev)
            rows.append((name, last, chg))
    return rows

def fmt_pct(x):
    return "N/A" if x is None else f"{x:+.2f}%"

# -------------------------
# NEWS HELPERS
# -------------------------
def clean_html(s: str):
    s = re.sub(r"<.*?>", " ", s or "")
    return re.sub(r"\s+", " ", s).strip()

def parse_time(e):
    for k in ("published", "updated"):
        if k in e:
            try:
                dt = dateparser.parse(e[k])
                if dt.tzinfo is None:
                    dt = dt.replace(tzinfo=timezone.utc)
                return dt.astimezone(timezone.utc)
            except:
                pass
    return None

AE_KEYS = [
    "asia","japan","boj","yen",
    "china","pboc","yuan","rmb","cpi","ppi","pmi","gdp","stimulus","property",
    "europe","ecb","eurozone","uk","bank of england",
    "tariff","trade","sanctions",
    "oil","gold","yield","treasury"
]

def fetch_news():
    cutoff = datetime.now(timezone.utc) - timedelta(hours=LOOKBACK_HOURS)
    rows = []
    for url in RSS_FEEDS:
        feed = feedparser.parse(url)
        src = feed.feed.get("title", url)
        src = src.split("|")[0].strip()
        for e in feed.entries:
            dt = parse_time(e)
            if dt and dt < cutoff:
                continue
            title = (e.get("title","") or "").strip()
            summ = clean_html(e.get("summary","") or "")
            text = (title + " " + summ).lower()
            if any(k in text for k in AE_KEYS):
                rows.append({"source": src, "title": title, "link": e.get("link","")})
    # 去重（按标题+链接）
    seen = set()
    out = []
    for r in rows:
        key = (r["title"], r["link"])
        if key in seen:
            continue
        seen.add(key)
        out.append(r)
    return out

def pick_top_events(news, n=6):
    if not news:
        return []
    # 简单优先级：宏观关键词命中越多越靠前
    priority = ["cpi","ppi","pmi","gdp","pboc","boj","ecb","bank of england","tariff","trade","yield","treasury"]
    def score(item):
        t = item["title"].lower()
        return sum(3 for k in priority if k in t)
    ranked = sorted(news, key=lambda x: (score(x), x["source"]), reverse=True)
    return ranked[:n]

def extract_china_data(news):
    """
    返回 dict: {"CPI":[...], "PPI":[...], "PMI":[...], "GDP":[...]}
    从标题中抓取含 China + (CPI/PPI/PMI/GDP) 的新闻
    """
    buckets = {"CPI": [], "PPI": [], "PMI": [], "GDP": []}
    for item in news:
        t = item["title"].lower()
        if "china" not in t and "chinese" not in t and "pboc" not in t and "yuan" not in t:
            continue
        if "cpi" in t:
            buckets["CPI"].append(item)
        if "ppi" in t:
            buckets["PPI"].append(item)
        if "pmi" in t:
            buckets["PMI"].append(item)
        if "gdp" in t:
            buckets["GDP"].append(item)
    # 每类最多 2 条，避免太长
    for k in buckets:
        buckets[k] = buckets[k][:2]
    return buckets

# -------------------------
# BUILD DATA
# -------------------------
eq = get_block(EQUITIES, "price")
bonds = get_block(BONDS, "yield")
fx = get_block(FX, "price")
cmd = get_block(COMMODITIES, "price")
news_all = fetch_news()
events = pick_top_events(news_all, n=6)
china_data = extract_china_data(news_all)

# -------------------------
# MARKET OVERVIEW (desk-style)
# -------------------------
eq_moves = [r[2] for r in eq if r[2] is not None]
avg_move = sum(eq_moves)/len(eq_moves) if eq_moves else 0

us10_bp = next((bp for (n, lvl, bp) in bonds if n == "US 10Y" and bp is not None), None)

overview_lines = []
if avg_move > 0.15:
    overview_lines.append("Asian and European equities traded higher overall, supported by steadier risk sentiment.")
elif avg_move < -0.15:
    overview_lines.append("Asian markets declined broadly and European markets were mixed, reflecting cautious positioning.")
else:
    overview_lines.append("Asian and European equities were mixed, with investors balancing macro signals and risk appetite.")

if us10_bp is not None:
    if us10_bp < -2:
        overview_lines.append("US Treasury yields edged lower, offering mild support to risk assets.")
    elif us10_bp > 2:
        overview_lines.append("US Treasury yields moved higher, keeping valuation sensitivity elevated.")
    else:
        overview_lines.append("US Treasury yields were little changed.")

overview_lines.append("FX was broadly stable, while gold and oil moved modestly on cross-asset flows.")
overview = " ".join(overview_lines)

# -------------------------
# BUILD REPORT TEXT (your template)
# -------------------------
date_str = datetime.now().strftime("%Y/%m/%d")

lines = []
lines.append(f"Daily Market Brief – {date_str}")
lines.append(f"2. {TITLE}")
lines.append("1. Market Overview")
lines.append(overview)
lines.append("")

lines.append("2. Key Indices")
lines.append("Equities")
for n,l,c in eq:
    lines.append(f"- {n}: {l:.2f}({fmt_pct(c)})" if l is not None else f"- {n}: N/A")

lines.append("Bonds")
for n,l,bp in bonds:
    lines.append(f"- {n}: {l:.4f} ({bp:+.2f}bp)" if l is not None else f"- {n}: N/A")

lines.append("FX")
for n,l,c in fx:
    lines.append(f"- {n} {l:.4f}({fmt_pct(c)})" if l is not None else f"- {n}: N/A")

lines.append("Commodities")
for n,l,c in cmd:
    lines.append(f"- {n}: {l:.2f}({fmt_pct(c)})" if l is not None else f"- {n}: N/A")

lines.append("")
lines.append("3. China economic data")
# 这里按你要的 CPI / GDP / PPI / PMI 顺序输出
order = ["CPI", "GDP", "PPI", "PMI"]
any_found = any(china_data[k] for k in order)

for k in order:
    lines.append(f"- {k}:")
    if china_data[k]:
        for item in china_data[k]:
            lines.append(f"  - {item['title']}  [{item['source']}]")
            if item.get("link"):
                lines.append(f"    {item['link']}")
    else:
        lines.append("  - No relevant headline detected in the current lookback window.")

if not any_found:
    lines.append("Note: This section is headline-based (RSS). If you want exact release dates/figures, we can add a calendar/API module later.")

lines.append("")
lines.append("4. Market Drivers & Interpretation")
lines.append(
    "Regional equity performance reflects sensitivity to global liquidity conditions and rate expectations. "
    "China-related macro developments and policy expectations remain key drivers of sentiment, while Europe reacts to growth and central-bank signals."
)

sources = ", ".join(sorted(set([x["source"] for x in events]))) if events else "(none)"
lines.append("")
lines.append(f"Sources: {sources}")

report_text = "\n".join(lines)

# 打印给你看
print(report_text)

# -------------------------
# WRITE INTO GOOGLE DOC (AE)
# -------------------------
# --- Google Service Account login ---
creds_json = json.loads(os.environ["GOOGLE_CREDENTIALS"])

credentials = service_account.Credentials.from_service_account_info(
    creds_json,
    scopes=["https://www.googleapis.com/auth/documents"]
)

docs = build("docs", "v1", credentials=credentials)

doc = docs.documents().get(documentId=DOC_ID).execute()
end_index = doc["body"]["content"][-1]["endIndex"]

requests = []
if end_index > 2:
    requests.append({
        "deleteContentRange": {"range": {"startIndex": 1, "endIndex": end_index - 1}}
    })

requests.append({
    "insertText": {"location": {"index": 1}, "text": report_text}
})

docs.documents().batchUpdate(documentId=DOC_ID, body={"requests": requests}).execute()
print("\n✅ AE Google Doc updated successfully.")
